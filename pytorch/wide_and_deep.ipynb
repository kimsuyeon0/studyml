{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wide and deep.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimsuyeon0/studyml/blob/master/pytorch/wide_and_deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jMDCUTVMLqMI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 신경망을 넓고 깊게 만드는 방법 "
      ]
    },
    {
      "metadata": {
        "id": "NrVrNK6NLQJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rzEg4NELePn7",
        "colab_type": "code",
        "outputId": "ef3ad4c1-f07a-4274-b5b7-ea6de0b29ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "xy=np.loadtxt('diabets.csv', delimiter=',', dtype=np.float32)\n",
        "x_data=Variable(torch.from_numpy(xy[:,0:-1]))\n",
        "y_data=Variable(torch.from_numpy(xy[:,[-1]]))\n",
        "\n",
        "print(x_data.data.shape)\n",
        "print(y_data.data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([759, 8])\n",
            "torch.Size([759, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qE5Mf-0OepmS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.l1=torch.nn.Linear(8,6)\n",
        "    self.l2=torch.nn.Linear(6,4)\n",
        "    self.l3=torch.nn.Linear(4,1)\n",
        "    \n",
        "    self.sigmoid=torch.nn.Sigmoid()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    \n",
        "    out1=self.sigmoid(self.l1(x))\n",
        "    out2=self.sigmoid(self.l2(out1))\n",
        "    y_pred=self.sigmoid(self.l3(out2))\n",
        "    return y_pred\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxXmO3T_gosh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mO7yqlHngpm4",
        "colab_type": "code",
        "outputId": "1573edf0-9bd9-4cfd-bec0-a63e5efbcea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "criterion=torch.nn.BCELoss(size_average=True)\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ou2JnndGg-Oo",
        "colab_type": "code",
        "outputId": "ec0e42ba-f832-4827-f00f-f5dc78cdbb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1794
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "        # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    print(epoch, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6770265698432922\n",
            "1 0.6743404269218445\n",
            "2 0.6718850135803223\n",
            "3 0.6696405410766602\n",
            "4 0.6675884127616882\n",
            "5 0.6657118797302246\n",
            "6 0.6639953851699829\n",
            "7 0.6624252200126648\n",
            "8 0.6609876751899719\n",
            "9 0.6596723794937134\n",
            "10 0.6584680676460266\n",
            "11 0.6573652625083923\n",
            "12 0.6563549637794495\n",
            "13 0.655430018901825\n",
            "14 0.6545827388763428\n",
            "15 0.6538048386573792\n",
            "16 0.6530935764312744\n",
            "17 0.6524405479431152\n",
            "18 0.6518418192863464\n",
            "19 0.6512924432754517\n",
            "20 0.6507894396781921\n",
            "21 0.6503275632858276\n",
            "22 0.649903416633606\n",
            "23 0.6495136022567749\n",
            "24 0.6491565704345703\n",
            "25 0.6488290429115295\n",
            "26 0.6485283970832825\n",
            "27 0.6482514142990112\n",
            "28 0.6479974985122681\n",
            "29 0.6477642059326172\n",
            "30 0.6475492119789124\n",
            "31 0.6473522186279297\n",
            "32 0.647171139717102\n",
            "33 0.6470043659210205\n",
            "34 0.6468515396118164\n",
            "35 0.6467107534408569\n",
            "36 0.6465815305709839\n",
            "37 0.6464623212814331\n",
            "38 0.6463520526885986\n",
            "39 0.6462521553039551\n",
            "40 0.6461589932441711\n",
            "41 0.6460738182067871\n",
            "42 0.6459944844245911\n",
            "43 0.6459222435951233\n",
            "44 0.6458557844161987\n",
            "45 0.6457942724227905\n",
            "46 0.6457372903823853\n",
            "47 0.6456853151321411\n",
            "48 0.6456369757652283\n",
            "49 0.6455928683280945\n",
            "50 0.6455516219139099\n",
            "51 0.645514190196991\n",
            "52 0.6454795598983765\n",
            "53 0.6454471945762634\n",
            "54 0.6454170346260071\n",
            "55 0.6453900933265686\n",
            "56 0.6453645825386047\n",
            "57 0.6453406810760498\n",
            "58 0.6453194618225098\n",
            "59 0.6452988386154175\n",
            "60 0.6452808976173401\n",
            "61 0.6452634930610657\n",
            "62 0.6452473402023315\n",
            "63 0.6452327966690063\n",
            "64 0.6452191472053528\n",
            "65 0.6452059745788574\n",
            "66 0.6451945900917053\n",
            "67 0.6451833844184875\n",
            "68 0.6451733112335205\n",
            "69 0.6451634168624878\n",
            "70 0.6451547145843506\n",
            "71 0.6451461315155029\n",
            "72 0.6451384425163269\n",
            "73 0.6451313495635986\n",
            "74 0.6451242566108704\n",
            "75 0.6451178193092346\n",
            "76 0.6451123356819153\n",
            "77 0.6451067924499512\n",
            "78 0.6451013684272766\n",
            "79 0.6450966596603394\n",
            "80 0.6450912952423096\n",
            "81 0.6450876593589783\n",
            "82 0.645082950592041\n",
            "83 0.6450791954994202\n",
            "84 0.6450753808021545\n",
            "85 0.6450716853141785\n",
            "86 0.6450682282447815\n",
            "87 0.6450657248497009\n",
            "88 0.6450618505477905\n",
            "89 0.6450592279434204\n",
            "90 0.645055890083313\n",
            "91 0.6450534462928772\n",
            "92 0.6450510025024414\n",
            "93 0.6450484991073608\n",
            "94 0.6450462937355042\n",
            "95 0.6450438499450684\n",
            "96 0.6450409889221191\n",
            "97 0.645039439201355\n",
            "98 0.6450369954109192\n",
            "99 0.6450346112251282\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}